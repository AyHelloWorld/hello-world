
gswyhq@gswyhq-PC:~ docker pull taskrabbit/elasticsearch-dump
Using default tag: latest
latest: Pulling from taskrabbit/elasticsearch-dump
1160f4abea84: Pull complete
6e17e6655d0c: Pull complete
Digest: sha256:06a1a35aa62fc3326565d5cbac428f42486889d813c99d38b0996c18e83e9f71
Status: Downloaded newer image for taskrabbit/elasticsearch-dump:latest

Example:
# 从一个机器迁移索引及数据到另一个机器:
# 第一步： 拷贝analyzer如分词
gswyhq@gswyhq-PC:~$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input=http://192.168.3.145:9200/dingding500_faq   --output=http://192.168.3.133:18200/dingding500_faq   --type=analyzer
# 第二步： 拷贝映射
gswyhq@gswyhq-PC:~$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input=http://192.168.3.105:9200/mingcijieshi   --output=http://192.168.3.133:9200/mingcijieshi   --type=mapping
# 第三步： 拷贝数据
gswyhq@gswyhq-PC:~$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input=http://192.168.3.105:9200/mingcijieshi   --output=http://192.168.3.133:9200/mingcijieshi   --type=data

# 若迁移数据需要提供登录认证：
gswyhq@gswyhq-PC:~/yhb/es_search$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input="http://192.168.3.105:9200/jrtz_kg_entity_synonyms_20180404_111151"   --output="http://elastic:web12008@192.168.3.145:9200/jrtz_kg_entity_synonyms_20180404_111151"  --type=data

以上数据迁移的时候，会丢失对应的索引别名信息；

docker run --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.250:9200/my_index \
  --output=http://192.168.3.105:9200/my_index \
  --type=mapping
docker run --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.250:9200/my_index \
  --output=http://192.168.3.105:9200/my_index \
  --type=data

# 备份索引数据到一个文件:
docker run --rm -ti -v /data:/tmp taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.250:9200/my_index \
  --output=/tmp/my_index_mapping.json \
  --type=mapping

gswyhq@gswyhq-PC:~/docker/elasticsearch$ docker run --rm  -ti -v $PWD/esdata:/data taskrabbit/elasticsearch-dump   --input=http://192.168.3.105:9200/all_baoxian_templates_answer_alias   --output=/data/all_baoxian_templates_answer_alias.json   --type=data

如果需要用 localhost 作为es的host：
docker run --net=host --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.105:9200/my_index \
  --output=http://localhost:9200/my_index \
  --type=data


若不使用docker，则需要安装数据导入、导出插件
　　sudo apt-get install nodejs
　　sudo apt-get install npm
　　sudo npm install elasticdump -g
从数据库导出某个索引数据到文件：
gswyhq@gswyhq-pc:~$ elasticdump --input=http://localhost:9200/music-index --output=/home/gswyhq/ambbr-ai/ambbr/music-index.json --all=true
从数据库导出所有索引数据到文件：
gswyhq@gswyhq-pc:~$ elasticdump --input=http://localhost:9200 --output=/home/gswyhq/ambbr-ai/ambbr/Elasticsearch_all_data.json --all=true

从文件导入数据到数据库：
gswyhq@gswyhq-pc:~$ elasticdump --input=/home/gswyhq/ambbr-ai/ambbr/music-index.json --output=http://localhost:9200/music-index3 --all=true

从一个数据库导出一个索引到另一个数据库：
gswyhq@gswyhq-pc:~$ elasticdump --input=http://localhost:9200/xplan_story_info --output=http://172.26.1.196:9200/xplan_story_info --all=true

elasticdump --input=http://localhost:9200/music-index --output=http://172.26.1.196:9200/music-index --all=true
elasticdump --input=http://172.26.1.196:9200/search-index/test --output=http://localhost:9200/qa-search-index/test --type=mapping
elasticdump --input=http://localhost:9200/qa-search-index/test --output=http://172.26.1.196:9200/qa-search-index/test --all=true


gswyhq@gswyhq-pc:~$ elasticdump --input=http://localhost:9200/music-index --output=http://172.26.1.196:9200/music-index --type=mapping
gswyhq@gswyhq-pc:~$ elasticdump --input=http://localhost:9200/music-index --output=http://172.26.1.196:9200/music-index --all=true


gswyhq@gswyhq-pc:~$ curl -XPUT localhost:9200/qa-search-index
gswyhq@gswyhq-pc:~$ curl -XPUT localhost:9200/qa-search-index/test/_mapping?pretty -d '{"test":{"properties":{"expression": {"type": "string"},"answer": {"type": "string"},"lib": {"type": "string"},"skill": {"type": "string"},"name": {"type": "string"},"id": {"type": "string"},"label": {"type": "string"},"keyword":{"type": "string"},"content": {"analyzer": "ik_max_word","type": "string"}}}}'

elasticdump --input=http://localhost:9200/qa-search-index --output=http://172.26.1.196:9200/qa-search-index --type=mapping
elasticdump --input=http://localhost:9200/qa-search-index --output=http://172.26.1.196:9200/qa-search-index --all=true

./elasticdump  --input=http://192.168.1.1:9200/original --output=http://192.168.1.2:9200/newCopy --type=mapping
--type=mapping ，意思是把原始索引的mapping结构迁移给目标索引。
然后在执行--type=data的
./elasticdump  --input=http://192.168.1.1:9200/original --output=http://192.168.1.2:9200/newCopy --type=data
就可以把数据迁移过去啦
如果索引很多，你还是懒得一个个去迁移，那么你可以改用这个命令：
./elasticdump  --input=http://192.168.1.1:9200/ --output=http://192.168.1.2:9200/ --all=true
加个--all=true，input与output里不需要把索引名加上，这样就可以自动把原机器上的所有索引迁移到目标机器


导出Mapping信息
elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.29   --output=http://192.168.100.72:9200/xmonitor-prd-2015.04.29  --type=mapping

导出数据
elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.28   --output=/usr/local/esdump/node-v0.12.2-linux-x64/data/xmonitor-prd-2015.04.28.json --type=data

导出数据到本地集群
elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.29   --output=http://192.168.100.72:9200/xmonitor-prd-2015.04.29 --type=data

# Copy an index from production to staging with analyzer and mapping:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=analyzer
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=data

# Backup index data to a file:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index_mapping.json \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index.json \
  --type=data
# Backup and index to a gzip using stdout:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=$ \
  | gzip > /data/my_index.json.gz

# Backup the results of a query to a file
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=query.json \
  --searchBody '{"query":{"term":{"username": "admin"}}}'

# Copy a single index from a elasticsearch:
elasticdump \
  --input=http://es.com:9200/api/search \
  --input-index=my_index \
  --output=http://es.com:9200/api/search \
  --output-index=my_index \
  --type=mapping

# Copy a single type:
elasticdump \
  --input=http://es.com:9200/api/search \
  --input-index=my_index/my_type \
  --output=http://es.com:9200/api/search \
  --output-index=my_index \
  --type=mapping

# Copy a single type:
elasticdump \
  --input=http://es.com:9200/api/search \
  --input-index=my_index/my_type \
  --output=http://es.com:9200/api/search \
  --output-index=my_index \
  --type=mapping


# 当是单机，单节点时，且版本也一致，可以直接复制对应索引的数据到另外服务器：
1、查询索引对应是uuid:
gswyhq@gswyhq-PC:~$ curl -XGET 'localhost:9200/_cat/indices?v'
health status index                            uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   blog                             u9cPLNNbTXKJfkXkPfrJ8A   5   1          1            0      5.4kb          5.4kb
yellow open   my_index                         i6cQ1GVaTC2hvpizSZv27Q   5   1          2            0     13.9kb         13.9kb
yellow open   baike                            B5_0Mbb-S1aHtKKJp1mbhw   5   1       4814            0      8.7mb          8.7mb
yellow open   ceshi_baike                      IPY7GXKlQgiLqN4E_CRN-w   5   1          3            0     21.7kb         21.7kb
yellow open   dingding500_faq                   mI8GODPAQ--NMgUIwqFDkw   5   1     139053            0     93.4mb         93.4mb
yellow open   dingding7500_faq                  1ijC2x6DQf2TMxUgbVDQ4Q   5   1    1647769            0    702.2mb        702.2mb
yellow open   baike_faq                        H3Q7LAUcQICWBrQXTFl-SQ   5   1          0            0       960b           960b
yellow open   jykl_noun_explanation NI693MdwSEuT9ejZk4g1Rw   5   1      46556            0    277.4mb        277.4mb
yellow open   xinxin_faq                     biFkTYQAT2myWlTsXQYwGw   5   1       1145            0      1.7mb          1.7mb
yellow open   jykl_faq              iIrJ4GrXSdiwKFNeocXRbg   5   1      46556        18956    451.2mb        451.2mb

2、复制数据目录
gswyhq@gswyhq-PC:~/docker/elasticsearch/esdata/nodes/0/indices$ ls
1ijC2x6DQf2TMxUgbVDQ4Q  biFkTYQAT2myWlTsXQYwGw  i6cQ1GVaTC2hvpizSZv27Q  IPY7GXKlQgiLqN4E_CRN-w  NI693MdwSEuT9ejZk4g1Rw
B5_0Mbb-S1aHtKKJp1mbhw  H3Q7LAUcQICWBrQXTFl-SQ  iIrJ4GrXSdiwKFNeocXRbg  mI8GODPAQ--NMgUIwqFDkw  u9cPLNNbTXKJfkXkPfrJ8A
gswyhq@gswyhq-PC:~/docker/elasticsearch/esdata/nodes/0/indices$ scp -r B5_0Mbb-S1aHtKKJp1mbhw new40:/home/ubuntu/docker/elasticsearch/esdata/nodes/0/indices/

以上会保留索引的别名信息。

# 更多的数据迁移使用帮助：
https://www.npmjs.com/package/elasticdump
